{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# movielens regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, get_feature_names\n",
    "from deepctr_torch.models import DeepFM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./movielens_sample.txt\")\n",
    "sparse_features = [\"movie_id\", \"user_id\",\n",
    "                       \"gender\", \"age\", \"occupation\", \"zip\"]\n",
    "target = ['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Label Encoding for sparse features,and do simple Transformation for dense features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.count #unique features for each sparse field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique())\n",
    "                              for feat in sparse_features]\n",
    "# nunique()返回唯一值的数量\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3.generate input data for model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_model_input = {name: train[name] for name in feature_names}\n",
    "test_model_input = {name: test[name] for name in feature_names}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Define Model,train,predict and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "use_cuda = False\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "\n",
    "history = model.fit(train_model_input, train[target].values,\n",
    "                    batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "pred_ans = model.predict(test_model_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test MSE\", round(mean_squared_error(\n",
    "        test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['rating'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multivalue-movielens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from deepctr_torch.inputs import SparseFeat, VarLenSparseFeat, get_feature_names\n",
    "from deepctr_torch.models import DeepFM\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map() 会根据提供的函数对指定序列做映射。\n",
    ">>> map(lambda x: x ** 2, [1, 2, 3, 4, 5])  # 使用 lambda 匿名函数\n",
    "[1, 4, 9, 16, 25]\n",
    " \n",
    "提供了两个列表，对相同位置的列表数据进行相加\n",
    ">>> map(lambda x, y: x + y, [1, 3, 5, 7, 9], [2, 4, 6, 8, 10])\n",
    "[3, 7, 11, 15, 19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以这样认为,lambda作为一个表达式，定义了一个匿名函数，上例的代码x为入口参数，x+1为函数体，用函数来表示为：\n",
    "非常容易理解，在这里lambda简化了函数定义的书写形式。是代码更为简洁，但是使用函数的定义方式更为直观，易理解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x):\n",
    "    key_ans = x.split('|')\n",
    "    for key in key_ans:\n",
    "        if key not in key2index:\n",
    "            # Notice : input value 0 is a special \"padding\",so we do not use 0 to encode valid feature for sequence input\n",
    "            key2index[key] = len(key2index) + 1\n",
    "    return list(map(lambda x: key2index[x], key_ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Label Encoding for sparse features,and process sequence features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "# preprocess the sequence feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key2index = {}\n",
    "# 给电影种类分类\n",
    "genres_list = list(map(split, data['genres'].values))\n",
    "genres_length = np.array(list(map(len, genres_list)))\n",
    "max_len = max(genres_length)\n",
    "# Notice : padding=`post`\n",
    "genres_list = pad_sequences(genres_list, maxlen=max_len, padding='post', )\n",
    "# 就是个padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genres_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.count #unique features for each sparse field and generate feature config for sequence feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique(), embedding_dim=4)\n",
    "                          for feat in sparse_features]\n",
    "\n",
    "varlen_feature_columns = [VarLenSparseFeat(SparseFeat('genres',\n",
    "                                                      vocabulary_size=len(key2index) + 1,\n",
    "                                                      embedding_dim=4),\n",
    "                                           maxlen=max_len, combiner='mean')]  # Notice : value 0 is for padding for sequence input feature\n",
    "\n",
    "linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varlen_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 3.generate input data for model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = {name: data[name] for name in sparse_features}  #\n",
    "model_input[\"genres\"] = genres_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "use_cuda = False\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "\n",
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "\n",
    "model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "history = model.fit(model_input, data[target].values,\n",
    "                    batch_size=256, epochs=100, verbose=2, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ans = model.predict(model_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTR预测例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "from deepctr_torch.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./criteo_sample.txt')\n",
    "\n",
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0, )\n",
    "target = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1      11\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "195     0\n",
       "196    21\n",
       "197     0\n",
       "198     0\n",
       "199    21\n",
       "Name: C1, Length: 200, dtype: int32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['C1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Label Encoding for sparse features,and do simple Transformation for dense features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.092362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.059628</td>\n",
       "      <td>0.117284</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.154739</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.077873</td>\n",
       "      <td>0.019934</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.505803</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.045977</td>\n",
       "      <td>0.033185</td>\n",
       "      <td>0.094967</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.028046</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.036945</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.067426</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.035783</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.040142</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.273029</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.206963</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>17</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.003168</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.014507</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063123</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.002901</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007662</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.072650</td>\n",
       "      <td>0.265781</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.491296</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label        I1        I2        I3        I4        I5        I6  \\\n",
       "0        0  0.000000  0.001332  0.092362  0.000000  0.034825  0.000000   \n",
       "1        0  0.000000  0.000000  0.006750  0.402299  0.059628  0.117284   \n",
       "2        0  0.000000  0.000333  0.000710  0.137931  0.003968  0.077873   \n",
       "3        0  0.000000  0.004664  0.000355  0.045977  0.033185  0.094967   \n",
       "4        0  0.000000  0.000333  0.036945  0.310345  0.003922  0.067426   \n",
       "..     ...       ...       ...       ...       ...       ...       ...   \n",
       "195      0  0.000000  0.000333  0.040142  0.034483  0.005984  0.273029   \n",
       "196      1  0.000000  0.000666  0.000355  0.011494  0.003168  0.005698   \n",
       "197      1  0.027027  0.000333  0.002131  0.034483  0.000000  0.000000   \n",
       "198      0  0.000000  0.007662  0.002131  0.252874  0.000400  0.072650   \n",
       "199      0  0.027027  0.000000  0.000000  0.000000  0.000272  0.000000   \n",
       "\n",
       "           I7        I8        I9  ...  C17  C18  C19  C20  C21  C22  C23  \\\n",
       "0    0.000000  0.673469  0.000000  ...    8   66    0    0    3    0    1   \n",
       "1    0.003322  0.714286  0.154739  ...    7   52    0    0   47    0    7   \n",
       "2    0.019934  0.714286  0.505803  ...    8   49    0    0   25    0    6   \n",
       "3    0.016611  0.081633  0.028046  ...    8   37    0    0  156    0    0   \n",
       "4    0.013289  0.653061  0.035783  ...    8   14    5    3    9    0    0   \n",
       "..        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "195  0.006645  0.061224  0.206963  ...    0   74    5    1   30    5    0   \n",
       "196  0.003322  0.244898  0.014507  ...    1   25    0    0  138    0    0   \n",
       "197  0.063123  0.061224  0.002901  ...    4   40   17    2   41    0    0   \n",
       "198  0.265781  0.367347  0.491296  ...    4    7   18    1  123    0    0   \n",
       "199  0.003322  0.000000  0.000000  ...    7   72    0    0    0    0    0   \n",
       "\n",
       "     C24  C25  C26  \n",
       "0     96    0    0  \n",
       "1    112    0    0  \n",
       "2     53    0    0  \n",
       "3     32    0    0  \n",
       "4      5    1   47  \n",
       "..   ...  ...  ...  \n",
       "195  118   17   48  \n",
       "196   68    0    0  \n",
       "197   12   16   11  \n",
       "198   10   16   49  \n",
       "199    0    0    0  \n",
       "\n",
       "[200 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.count #unique features for each sparse field,and record dense feature field name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique())\n",
    "                          for feat in sparse_features] + [DenseFeat(feat, 1, )\n",
    "                                                          for feat in dense_features]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(\n",
    "    linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeat(name='C1', vocabulary_size=27, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C1', group_name='default_group'),\n",
       " SparseFeat(name='C2', vocabulary_size=92, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C2', group_name='default_group'),\n",
       " SparseFeat(name='C3', vocabulary_size=172, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C3', group_name='default_group'),\n",
       " SparseFeat(name='C4', vocabulary_size=157, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C4', group_name='default_group'),\n",
       " SparseFeat(name='C5', vocabulary_size=12, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C5', group_name='default_group'),\n",
       " SparseFeat(name='C6', vocabulary_size=7, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C6', group_name='default_group'),\n",
       " SparseFeat(name='C7', vocabulary_size=183, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C7', group_name='default_group'),\n",
       " SparseFeat(name='C8', vocabulary_size=19, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C8', group_name='default_group'),\n",
       " SparseFeat(name='C9', vocabulary_size=2, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C9', group_name='default_group'),\n",
       " SparseFeat(name='C10', vocabulary_size=142, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C10', group_name='default_group'),\n",
       " SparseFeat(name='C11', vocabulary_size=173, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C11', group_name='default_group'),\n",
       " SparseFeat(name='C12', vocabulary_size=170, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C12', group_name='default_group'),\n",
       " SparseFeat(name='C13', vocabulary_size=166, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C13', group_name='default_group'),\n",
       " SparseFeat(name='C14', vocabulary_size=14, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C14', group_name='default_group'),\n",
       " SparseFeat(name='C15', vocabulary_size=170, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C15', group_name='default_group'),\n",
       " SparseFeat(name='C16', vocabulary_size=168, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C16', group_name='default_group'),\n",
       " SparseFeat(name='C17', vocabulary_size=9, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C17', group_name='default_group'),\n",
       " SparseFeat(name='C18', vocabulary_size=127, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C18', group_name='default_group'),\n",
       " SparseFeat(name='C19', vocabulary_size=44, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C19', group_name='default_group'),\n",
       " SparseFeat(name='C20', vocabulary_size=4, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C20', group_name='default_group'),\n",
       " SparseFeat(name='C21', vocabulary_size=169, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C21', group_name='default_group'),\n",
       " SparseFeat(name='C22', vocabulary_size=6, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C22', group_name='default_group'),\n",
       " SparseFeat(name='C23', vocabulary_size=10, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C23', group_name='default_group'),\n",
       " SparseFeat(name='C24', vocabulary_size=125, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C24', group_name='default_group'),\n",
       " SparseFeat(name='C25', vocabulary_size=20, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C25', group_name='default_group'),\n",
       " SparseFeat(name='C26', vocabulary_size=90, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='C26', group_name='default_group'),\n",
       " DenseFeat(name='I1', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I2', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I3', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I4', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I5', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I6', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I7', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I8', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I9', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I10', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I11', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I12', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I13', dimension=1, dtype='float32')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.generate input data for model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)\n",
    "\n",
    "train_model_input = {name: train[name] for name in feature_names}\n",
    "test_model_input = {name: test[name] for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.092362</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>0.402299</td>\n",
       "      <td>0.059628</td>\n",
       "      <td>0.117284</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.154739</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.077873</td>\n",
       "      <td>0.019934</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.505803</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.045977</td>\n",
       "      <td>0.033185</td>\n",
       "      <td>0.094967</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.028046</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.036945</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.067426</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.035783</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022380</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.028965</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.044487</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123584</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.472921</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>0.010657</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.109635</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.121857</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.012789</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.009233</td>\n",
       "      <td>0.103039</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.130561</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.264368</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>0.022244</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        I1        I2        I3        I4        I5        I6  \\\n",
       "0      0  0.000000  0.001332  0.092362  0.000000  0.034825  0.000000   \n",
       "1      0  0.000000  0.000000  0.006750  0.402299  0.059628  0.117284   \n",
       "2      0  0.000000  0.000333  0.000710  0.137931  0.003968  0.077873   \n",
       "3      0  0.000000  0.004664  0.000355  0.045977  0.033185  0.094967   \n",
       "4      0  0.000000  0.000333  0.036945  0.310345  0.003922  0.067426   \n",
       "5      0  0.000000  0.000000  0.022380  0.459770  0.002898  0.028965   \n",
       "6      0  0.000000  0.123584  0.001421  0.011494  0.003522  0.030864   \n",
       "7      1  0.513514  0.003664  0.010657  0.114943  0.000002  0.001425   \n",
       "8      0  0.000000  0.000333  0.012789  0.252874  0.009233  0.103039   \n",
       "9      0  0.054054  0.003997  0.002842  0.264368  0.000059  0.005223   \n",
       "\n",
       "         I7        I8        I9  ...  C17  C18  C19  C20  C21  C22  C23  C24  \\\n",
       "0  0.000000  0.673469  0.000000  ...    8   66    0    0    3    0    1   96   \n",
       "1  0.003322  0.714286  0.154739  ...    7   52    0    0   47    0    7  112   \n",
       "2  0.019934  0.714286  0.505803  ...    8   49    0    0   25    0    6   53   \n",
       "3  0.016611  0.081633  0.028046  ...    8   37    0    0  156    0    0   32   \n",
       "4  0.013289  0.653061  0.035783  ...    8   14    5    3    9    0    0    5   \n",
       "5  0.013289  0.755102  0.044487  ...    8  105    5    3   77    0    0   13   \n",
       "6  0.046512  0.510204  0.472921  ...    4   46   18    3   58    0    2   41   \n",
       "7  0.109635  0.959184  0.121857  ...    8   80    5    1  128    0    0   12   \n",
       "8  0.029900  0.714286  0.130561  ...    8   57    0    0  113    0    9   12   \n",
       "9  0.006645  0.163265  0.022244  ...    0   95    5    2   28    0    8   34   \n",
       "\n",
       "   C25  C26  \n",
       "0    0    0  \n",
       "1    0    0  \n",
       "2    0    0  \n",
       "3    0    0  \n",
       "4    1   47  \n",
       "5    1   34  \n",
       "6    3   71  \n",
       "7   16   17  \n",
       "8    0    0  \n",
       "9   11   74  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Define Model,train,predict,evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 128 samples, validate on 32 samples, 4 steps per epoch\n",
      "Epoch 1/70\n",
      "0s - loss:  0.6166 - binary_crossentropy:  0.6166 - auc:  0.5453 - val_binary_crossentropy:  0.5793 - val_auc:  0.7246\n",
      "Epoch 2/70\n",
      "0s - loss:  0.4696 - binary_crossentropy:  0.4696 - auc:  0.9768 - val_binary_crossentropy:  0.5946 - val_auc:  0.6377\n",
      "Epoch 3/70\n",
      "0s - loss:  0.3474 - binary_crossentropy:  0.3474 - auc:  1.0000 - val_binary_crossentropy:  0.6003 - val_auc:  0.5266\n",
      "Epoch 4/70\n",
      "0s - loss:  0.1872 - binary_crossentropy:  0.1872 - auc:  1.0000 - val_binary_crossentropy:  0.6505 - val_auc:  0.5024\n",
      "Epoch 5/70\n",
      "0s - loss:  0.0954 - binary_crossentropy:  0.0954 - auc:  1.0000 - val_binary_crossentropy:  0.7233 - val_auc:  0.4831\n",
      "Epoch 6/70\n",
      "0s - loss:  0.0582 - binary_crossentropy:  0.0582 - auc:  1.0000 - val_binary_crossentropy:  0.7743 - val_auc:  0.4879\n",
      "Epoch 7/70\n",
      "0s - loss:  0.0398 - binary_crossentropy:  0.0398 - auc:  1.0000 - val_binary_crossentropy:  0.8263 - val_auc:  0.4831\n",
      "Epoch 8/70\n",
      "0s - loss:  0.0293 - binary_crossentropy:  0.0293 - auc:  1.0000 - val_binary_crossentropy:  0.8553 - val_auc:  0.4783\n",
      "Epoch 9/70\n",
      "0s - loss:  0.0225 - binary_crossentropy:  0.0225 - auc:  1.0000 - val_binary_crossentropy:  0.8799 - val_auc:  0.4783\n",
      "Epoch 10/70\n",
      "0s - loss:  0.0179 - binary_crossentropy:  0.0179 - auc:  1.0000 - val_binary_crossentropy:  0.9071 - val_auc:  0.4783\n",
      "Epoch 11/70\n",
      "0s - loss:  0.0147 - binary_crossentropy:  0.0147 - auc:  1.0000 - val_binary_crossentropy:  0.9264 - val_auc:  0.4734\n",
      "Epoch 12/70\n",
      "0s - loss:  0.0123 - binary_crossentropy:  0.0123 - auc:  1.0000 - val_binary_crossentropy:  0.9505 - val_auc:  0.4734\n",
      "Epoch 13/70\n",
      "0s - loss:  0.0106 - binary_crossentropy:  0.0106 - auc:  1.0000 - val_binary_crossentropy:  0.9668 - val_auc:  0.4734\n",
      "Epoch 14/70\n",
      "0s - loss:  0.0091 - binary_crossentropy:  0.0091 - auc:  1.0000 - val_binary_crossentropy:  0.9787 - val_auc:  0.4734\n",
      "Epoch 15/70\n",
      "0s - loss:  0.0080 - binary_crossentropy:  0.0080 - auc:  1.0000 - val_binary_crossentropy:  0.9969 - val_auc:  0.4734\n",
      "Epoch 16/70\n",
      "0s - loss:  0.0071 - binary_crossentropy:  0.0071 - auc:  1.0000 - val_binary_crossentropy:  1.0041 - val_auc:  0.4734\n",
      "Epoch 17/70\n",
      "0s - loss:  0.0064 - binary_crossentropy:  0.0064 - auc:  1.0000 - val_binary_crossentropy:  1.0189 - val_auc:  0.4734\n",
      "Epoch 18/70\n",
      "0s - loss:  0.0058 - binary_crossentropy:  0.0058 - auc:  1.0000 - val_binary_crossentropy:  1.0304 - val_auc:  0.4734\n",
      "Epoch 19/70\n",
      "0s - loss:  0.0053 - binary_crossentropy:  0.0053 - auc:  1.0000 - val_binary_crossentropy:  1.0392 - val_auc:  0.4734\n",
      "Epoch 20/70\n",
      "0s - loss:  0.0048 - binary_crossentropy:  0.0048 - auc:  1.0000 - val_binary_crossentropy:  1.0539 - val_auc:  0.4734\n",
      "Epoch 21/70\n",
      "0s - loss:  0.0045 - binary_crossentropy:  0.0045 - auc:  1.0000 - val_binary_crossentropy:  1.0599 - val_auc:  0.4734\n",
      "Epoch 22/70\n",
      "0s - loss:  0.0041 - binary_crossentropy:  0.0041 - auc:  1.0000 - val_binary_crossentropy:  1.0707 - val_auc:  0.4734\n",
      "Epoch 23/70\n",
      "0s - loss:  0.0038 - binary_crossentropy:  0.0038 - auc:  1.0000 - val_binary_crossentropy:  1.0761 - val_auc:  0.4734\n",
      "Epoch 24/70\n",
      "0s - loss:  0.0036 - binary_crossentropy:  0.0036 - auc:  1.0000 - val_binary_crossentropy:  1.0857 - val_auc:  0.4734\n",
      "Epoch 25/70\n",
      "0s - loss:  0.0034 - binary_crossentropy:  0.0034 - auc:  1.0000 - val_binary_crossentropy:  1.0950 - val_auc:  0.4734\n",
      "Epoch 26/70\n",
      "0s - loss:  0.0032 - binary_crossentropy:  0.0032 - auc:  1.0000 - val_binary_crossentropy:  1.1002 - val_auc:  0.4734\n",
      "Epoch 27/70\n",
      "0s - loss:  0.0030 - binary_crossentropy:  0.0030 - auc:  1.0000 - val_binary_crossentropy:  1.1095 - val_auc:  0.4734\n",
      "Epoch 28/70\n",
      "0s - loss:  0.0028 - binary_crossentropy:  0.0028 - auc:  1.0000 - val_binary_crossentropy:  1.1145 - val_auc:  0.4734\n",
      "Epoch 29/70\n",
      "0s - loss:  0.0027 - binary_crossentropy:  0.0027 - auc:  1.0000 - val_binary_crossentropy:  1.1239 - val_auc:  0.4734\n",
      "Epoch 30/70\n",
      "0s - loss:  0.0025 - binary_crossentropy:  0.0025 - auc:  1.0000 - val_binary_crossentropy:  1.1270 - val_auc:  0.4686\n",
      "Epoch 31/70\n",
      "0s - loss:  0.0024 - binary_crossentropy:  0.0024 - auc:  1.0000 - val_binary_crossentropy:  1.1346 - val_auc:  0.4686\n",
      "Epoch 32/70\n",
      "0s - loss:  0.0023 - binary_crossentropy:  0.0023 - auc:  1.0000 - val_binary_crossentropy:  1.1384 - val_auc:  0.4638\n",
      "Epoch 33/70\n",
      "0s - loss:  0.0022 - binary_crossentropy:  0.0022 - auc:  1.0000 - val_binary_crossentropy:  1.1440 - val_auc:  0.4638\n",
      "Epoch 34/70\n",
      "0s - loss:  0.0021 - binary_crossentropy:  0.0021 - auc:  1.0000 - val_binary_crossentropy:  1.1512 - val_auc:  0.4638\n",
      "Epoch 35/70\n",
      "0s - loss:  0.0020 - binary_crossentropy:  0.0020 - auc:  1.0000 - val_binary_crossentropy:  1.1548 - val_auc:  0.4638\n",
      "Epoch 36/70\n",
      "0s - loss:  0.0019 - binary_crossentropy:  0.0019 - auc:  1.0000 - val_binary_crossentropy:  1.1595 - val_auc:  0.4589\n",
      "Epoch 37/70\n",
      "0s - loss:  0.0019 - binary_crossentropy:  0.0019 - auc:  1.0000 - val_binary_crossentropy:  1.1652 - val_auc:  0.4589\n",
      "Epoch 38/70\n",
      "0s - loss:  0.0018 - binary_crossentropy:  0.0018 - auc:  1.0000 - val_binary_crossentropy:  1.1708 - val_auc:  0.4589\n",
      "Epoch 39/70\n",
      "0s - loss:  0.0017 - binary_crossentropy:  0.0017 - auc:  1.0000 - val_binary_crossentropy:  1.1729 - val_auc:  0.4589\n",
      "Epoch 40/70\n",
      "0s - loss:  0.0017 - binary_crossentropy:  0.0017 - auc:  1.0000 - val_binary_crossentropy:  1.1795 - val_auc:  0.4589\n",
      "Epoch 41/70\n",
      "0s - loss:  0.0016 - binary_crossentropy:  0.0016 - auc:  1.0000 - val_binary_crossentropy:  1.1845 - val_auc:  0.4589\n",
      "Epoch 42/70\n",
      "0s - loss:  0.0015 - binary_crossentropy:  0.0015 - auc:  1.0000 - val_binary_crossentropy:  1.1879 - val_auc:  0.4589\n",
      "Epoch 43/70\n",
      "0s - loss:  0.0015 - binary_crossentropy:  0.0015 - auc:  1.0000 - val_binary_crossentropy:  1.1922 - val_auc:  0.4589\n",
      "Epoch 44/70\n",
      "0s - loss:  0.0015 - binary_crossentropy:  0.0015 - auc:  1.0000 - val_binary_crossentropy:  1.1975 - val_auc:  0.4589\n",
      "Epoch 45/70\n",
      "0s - loss:  0.0014 - binary_crossentropy:  0.0014 - auc:  1.0000 - val_binary_crossentropy:  1.2008 - val_auc:  0.4589\n",
      "Epoch 46/70\n",
      "0s - loss:  0.0014 - binary_crossentropy:  0.0014 - auc:  1.0000 - val_binary_crossentropy:  1.2027 - val_auc:  0.4589\n",
      "Epoch 47/70\n",
      "0s - loss:  0.0013 - binary_crossentropy:  0.0013 - auc:  1.0000 - val_binary_crossentropy:  1.2071 - val_auc:  0.4589\n",
      "Epoch 48/70\n",
      "0s - loss:  0.0013 - binary_crossentropy:  0.0013 - auc:  1.0000 - val_binary_crossentropy:  1.2110 - val_auc:  0.4589\n",
      "Epoch 49/70\n",
      "0s - loss:  0.0013 - binary_crossentropy:  0.0013 - auc:  1.0000 - val_binary_crossentropy:  1.2155 - val_auc:  0.4589\n",
      "Epoch 50/70\n",
      "0s - loss:  0.0012 - binary_crossentropy:  0.0012 - auc:  1.0000 - val_binary_crossentropy:  1.2180 - val_auc:  0.4589\n",
      "Epoch 51/70\n",
      "0s - loss:  0.0012 - binary_crossentropy:  0.0012 - auc:  1.0000 - val_binary_crossentropy:  1.2226 - val_auc:  0.4589\n",
      "Epoch 52/70\n",
      "0s - loss:  0.0012 - binary_crossentropy:  0.0012 - auc:  1.0000 - val_binary_crossentropy:  1.2248 - val_auc:  0.4589\n",
      "Epoch 53/70\n",
      "0s - loss:  0.0011 - binary_crossentropy:  0.0011 - auc:  1.0000 - val_binary_crossentropy:  1.2276 - val_auc:  0.4589\n",
      "Epoch 54/70\n",
      "0s - loss:  0.0011 - binary_crossentropy:  0.0011 - auc:  1.0000 - val_binary_crossentropy:  1.2314 - val_auc:  0.4589\n",
      "Epoch 55/70\n",
      "0s - loss:  0.0011 - binary_crossentropy:  0.0011 - auc:  1.0000 - val_binary_crossentropy:  1.2340 - val_auc:  0.4589\n",
      "Epoch 56/70\n",
      "0s - loss:  0.0010 - binary_crossentropy:  0.0010 - auc:  1.0000 - val_binary_crossentropy:  1.2378 - val_auc:  0.4589\n",
      "Epoch 57/70\n",
      "0s - loss:  0.0010 - binary_crossentropy:  0.0010 - auc:  1.0000 - val_binary_crossentropy:  1.2395 - val_auc:  0.4589\n",
      "Epoch 58/70\n",
      "0s - loss:  0.0010 - binary_crossentropy:  0.0010 - auc:  1.0000 - val_binary_crossentropy:  1.2444 - val_auc:  0.4589\n",
      "Epoch 59/70\n",
      "0s - loss:  0.0010 - binary_crossentropy:  0.0010 - auc:  1.0000 - val_binary_crossentropy:  1.2473 - val_auc:  0.4589\n",
      "Epoch 60/70\n",
      "0s - loss:  0.0010 - binary_crossentropy:  0.0010 - auc:  1.0000 - val_binary_crossentropy:  1.2494 - val_auc:  0.4589\n",
      "Epoch 61/70\n",
      "0s - loss:  0.0009 - binary_crossentropy:  0.0009 - auc:  1.0000 - val_binary_crossentropy:  1.2533 - val_auc:  0.4589\n",
      "Epoch 62/70\n",
      "0s - loss:  0.0009 - binary_crossentropy:  0.0009 - auc:  1.0000 - val_binary_crossentropy:  1.2553 - val_auc:  0.4589\n",
      "Epoch 63/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss:  0.0009 - binary_crossentropy:  0.0009 - auc:  1.0000 - val_binary_crossentropy:  1.2575 - val_auc:  0.4589\n",
      "Epoch 64/70\n",
      "0s - loss:  0.0009 - binary_crossentropy:  0.0009 - auc:  1.0000 - val_binary_crossentropy:  1.2604 - val_auc:  0.4589\n",
      "Epoch 65/70\n",
      "0s - loss:  0.0009 - binary_crossentropy:  0.0009 - auc:  1.0000 - val_binary_crossentropy:  1.2634 - val_auc:  0.4589\n",
      "Epoch 66/70\n",
      "0s - loss:  0.0008 - binary_crossentropy:  0.0008 - auc:  1.0000 - val_binary_crossentropy:  1.2656 - val_auc:  0.4589\n",
      "Epoch 67/70\n",
      "0s - loss:  0.0008 - binary_crossentropy:  0.0008 - auc:  1.0000 - val_binary_crossentropy:  1.2677 - val_auc:  0.4589\n",
      "Epoch 68/70\n",
      "0s - loss:  0.0008 - binary_crossentropy:  0.0008 - auc:  1.0000 - val_binary_crossentropy:  1.2715 - val_auc:  0.4589\n",
      "Epoch 69/70\n",
      "0s - loss:  0.0008 - binary_crossentropy:  0.0008 - auc:  1.0000 - val_binary_crossentropy:  1.2719 - val_auc:  0.4589\n",
      "Epoch 70/70\n",
      "0s - loss:  0.0008 - binary_crossentropy:  0.0008 - auc:  1.0000 - val_binary_crossentropy:  1.2760 - val_auc:  0.4589\n",
      "\n",
      "test LogLoss 1.5645\n",
      "test AUC 0.4514\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "use_cuda = False\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "\n",
    "model = DeepFM(linear_feature_columns=linear_feature_columns, dnn_feature_columns=dnn_feature_columns,\n",
    "               task='binary',\n",
    "               l2_reg_embedding=1e-5, device=device)\n",
    "\n",
    "model.compile(\"adagrad\", \"binary_crossentropy\",\n",
    "              metrics=[\"binary_crossentropy\", \"auc\"], )\n",
    "model.fit(train_model_input, train[target].values,\n",
    "          batch_size=32, epochs=70, validation_split=0.2, verbose=2)\n",
    "\n",
    "pred_ans = model.predict(test_model_input, 256)\n",
    "print(\"\")\n",
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model.predict(train_model_input, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.10217617e-04],\n",
       "       [3.01186046e-05],\n",
       "       [4.93904190e-05],\n",
       "       [1.15745264e-04],\n",
       "       [1.18597108e-03],\n",
       "       [6.59942234e-05],\n",
       "       [1.48401727e-04],\n",
       "       [2.38176781e-05],\n",
       "       [2.17674722e-04],\n",
       "       [4.35395777e-05],\n",
       "       [1.07054751e-04],\n",
       "       [9.37636869e-05],\n",
       "       [3.25871442e-05],\n",
       "       [6.31685689e-05],\n",
       "       [5.89048832e-05],\n",
       "       [3.35569275e-05],\n",
       "       [1.97419959e-05],\n",
       "       [8.12507205e-05],\n",
       "       [9.98389482e-01],\n",
       "       [9.94843602e-01],\n",
       "       [9.96833980e-01],\n",
       "       [9.97778952e-01],\n",
       "       [2.94820202e-04],\n",
       "       [1.45310900e-04],\n",
       "       [2.84458547e-05],\n",
       "       [1.88346326e-04],\n",
       "       [5.05146782e-05],\n",
       "       [9.97907043e-01],\n",
       "       [4.84730117e-05],\n",
       "       [1.75593814e-04],\n",
       "       [1.07931955e-04],\n",
       "       [3.58702964e-05],\n",
       "       [5.09825077e-05],\n",
       "       [9.97884810e-01],\n",
       "       [9.96704876e-01],\n",
       "       [9.97035742e-01],\n",
       "       [4.56492708e-05],\n",
       "       [4.02543737e-05],\n",
       "       [9.37036166e-05],\n",
       "       [9.97111440e-01],\n",
       "       [9.98131573e-01],\n",
       "       [2.02772237e-04],\n",
       "       [1.66519356e-04],\n",
       "       [1.45131300e-04],\n",
       "       [2.28181580e-05],\n",
       "       [3.20747531e-05],\n",
       "       [7.20071985e-05],\n",
       "       [9.94808674e-01],\n",
       "       [2.54343668e-05],\n",
       "       [7.66865851e-05],\n",
       "       [6.98734366e-05],\n",
       "       [8.13712104e-05],\n",
       "       [2.21801369e-04],\n",
       "       [7.20698517e-05],\n",
       "       [9.95193899e-01],\n",
       "       [2.47148673e-05],\n",
       "       [2.64068862e-04],\n",
       "       [3.10525720e-05],\n",
       "       [5.77600076e-05],\n",
       "       [4.31949156e-05],\n",
       "       [1.20841571e-04],\n",
       "       [4.41031443e-05],\n",
       "       [1.13786940e-04],\n",
       "       [9.95888889e-01],\n",
       "       [9.24561245e-05],\n",
       "       [5.92217584e-05],\n",
       "       [6.33246600e-05],\n",
       "       [3.29071772e-05],\n",
       "       [9.98381138e-01],\n",
       "       [1.23219470e-05],\n",
       "       [7.62617201e-05],\n",
       "       [9.97036219e-01],\n",
       "       [6.52084360e-04],\n",
       "       [4.90996354e-05],\n",
       "       [7.61265037e-05],\n",
       "       [4.22686135e-05],\n",
       "       [9.95413721e-01],\n",
       "       [5.32429767e-05],\n",
       "       [1.16844662e-04],\n",
       "       [9.98099267e-01],\n",
       "       [1.09716369e-04],\n",
       "       [6.05719324e-05],\n",
       "       [9.95588541e-01],\n",
       "       [1.15525952e-04],\n",
       "       [4.32428060e-05],\n",
       "       [9.87728999e-05],\n",
       "       [6.08670016e-05],\n",
       "       [1.08504988e-04],\n",
       "       [4.22980884e-05],\n",
       "       [3.25410583e-05],\n",
       "       [9.98213053e-01],\n",
       "       [9.96144891e-01],\n",
       "       [6.13043594e-05],\n",
       "       [6.70478621e-04],\n",
       "       [9.96894479e-01],\n",
       "       [3.05262656e-05],\n",
       "       [2.80154836e-05],\n",
       "       [9.97917473e-01],\n",
       "       [9.96570110e-01],\n",
       "       [8.16687170e-05],\n",
       "       [9.98215437e-01],\n",
       "       [1.66919956e-04],\n",
       "       [4.18651252e-05],\n",
       "       [4.48339735e-04],\n",
       "       [9.96302485e-01],\n",
       "       [2.25661806e-05],\n",
       "       [3.35042394e-04],\n",
       "       [5.38458007e-05],\n",
       "       [3.93942697e-04],\n",
       "       [9.97489452e-01],\n",
       "       [3.26787012e-05],\n",
       "       [3.15527461e-04],\n",
       "       [9.97846484e-01],\n",
       "       [9.96959209e-01],\n",
       "       [8.06090975e-05],\n",
       "       [1.41822544e-04],\n",
       "       [6.92285030e-05],\n",
       "       [6.44745378e-05],\n",
       "       [6.43533494e-05],\n",
       "       [5.75947779e-05],\n",
       "       [1.65195252e-05],\n",
       "       [2.27398687e-05],\n",
       "       [2.69396696e-04],\n",
       "       [9.96841431e-01],\n",
       "       [2.98716877e-05],\n",
       "       [1.47603379e-04],\n",
       "       [1.23164398e-04],\n",
       "       [1.85472993e-04],\n",
       "       [7.56824575e-03],\n",
       "       [1.52925765e-02],\n",
       "       [7.03839138e-02],\n",
       "       [7.71163451e-03],\n",
       "       [2.34001465e-02],\n",
       "       [4.30899411e-02],\n",
       "       [6.86635263e-04],\n",
       "       [1.41898081e-01],\n",
       "       [2.77987532e-02],\n",
       "       [9.89622669e-04],\n",
       "       [3.11330110e-02],\n",
       "       [1.76839624e-03],\n",
       "       [2.46824361e-02],\n",
       "       [5.61025110e-04],\n",
       "       [3.15286964e-02],\n",
       "       [1.54672777e-02],\n",
       "       [1.44344866e-01],\n",
       "       [1.32823400e-02],\n",
       "       [1.86236098e-03],\n",
       "       [1.82053000e-01],\n",
       "       [1.04956709e-01],\n",
       "       [7.07440719e-04],\n",
       "       [7.34524243e-03],\n",
       "       [2.04623817e-03],\n",
       "       [1.04997590e-01],\n",
       "       [1.16890781e-01],\n",
       "       [2.79164881e-01],\n",
       "       [2.45706644e-02],\n",
       "       [2.25049886e-03],\n",
       "       [1.42188013e-01],\n",
       "       [6.75015748e-02],\n",
       "       [9.58899152e-04]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
