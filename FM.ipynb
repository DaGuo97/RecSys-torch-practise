{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='./data/ratings.csv'\n",
    "movie_file_name='./data/movies.csv'\n",
    "\n",
    "df=pd.read_csv(file_name,sep=',')\n",
    "df_sort=df.sort_values(by=['userId','timestamp'],\n",
    "                       ascending=(True,False))\n",
    "user_num=df_sort['userId'].max()\n",
    "item_num=df_sort['movieId'].max()\n",
    "\n",
    "movie_df=pd.read_csv(movie_file_name,sep=',')\n",
    "# print(df_sort.head())\n",
    "# print(movie_df.head()) # movieId,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_last_movie=[]\n",
    "item_count=[]\n",
    "for i in range(1,user_num+1):\n",
    "    user_last_movie.append([i,df_sort.loc[df_sort['userId']==i]['movieId'].iloc[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_movie=np.zeros([df_sort.shape[0],2])\n",
    "for user,movie in user_last_movie:\n",
    "    last_movie[df_sort['userId']==user]=[user,movie]\n",
    "\n",
    "last_movie_df=pd.DataFrame(last_movie,columns=['userId','lastMovie'],dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df=pd.DataFrame(np.hstack([df_sort.values,last_movie_df.values]),columns=['user','item','rating','timestamp','niubi','last_movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=concat_df.iloc[:,[0,1,2,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./data/rating_lastMovie.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=pd.read_csv('./data/rating_lastMovie.csv',usecols=['user','item','rating','last_movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.sample(frac=1.0)  # 全部打乱\n",
    "cut_idx = int(round(0.2 * data_df.shape[0]))\n",
    "df_test, df_train = data_df.iloc[:cut_idx], data_df.iloc[cut_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test.shape,df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('./data/rating_train.csv')\n",
    "df_test.to_csv('./data/rating_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(),df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.生成特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('./data/rating_train.csv',usecols=['user','item','rating','last_movie'])\n",
    "df_test=pd.read_csv('./data/rating_test.csv',usecols=['user','item','rating','last_movie'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(),df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df_train #时间戳是不相关信息，可以去掉\n",
    "test=df_test\n",
    "\n",
    "# DictVectorizer会把数字识别为连续特征，这里把用户id、item id和lastmovie强制转为 catogorical identifier\n",
    "train[\"item\"]=train[\"item\"].apply(lambda x:\"c\"+str(x))\n",
    "train[\"user\"]=train[\"user\"].apply(lambda  x:\"u\"+str(x))\n",
    "train[\"last_movie\"]=train[\"last_movie\"].apply(lambda  x:\"l\"+str(x))\n",
    "\n",
    "test[\"item\"]=test[\"item\"].apply(lambda x:\"c\"+str(x))\n",
    "test[\"user\"]=test[\"user\"].apply(lambda x:\"u\"+str(x))\n",
    "test[\"last_movie\"]=test[\"last_movie\"].apply(lambda  x:\"l\"+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 在构造特征向量时应该不考虑评分，只考虑用户数和电影数\n",
    "train_no_rating=train.drop(['rating'],axis=1)\n",
    "test_no_rating=test.drop(['rating'],axis=1)\n",
    "all_df=pd.concat([train_no_rating,test_no_rating])\n",
    "# all_df=pd.concat([train,test])\n",
    "data_num=all_df.shape\n",
    "print(\"all_df shape\",all_df.shape)\n",
    "# 打印前10行\n",
    "# print(\"all_df head\",all_df.head(10))\n",
    "\n",
    "# 进行特征向量化,有多少特征，就会新创建多少列\n",
    "vec=DictVectorizer()\n",
    "vec.fit_transform(all_df.to_dict(orient='record'))\n",
    "# 合并训练集与验证集，是为了one hot,用完可以释放\n",
    "del all_df\n",
    "\n",
    "x_train=vec.transform(train.to_dict(orient='record')).toarray()\n",
    "x_test=vec.transform(test.to_dict(orient='record')).toarray()\n",
    "# print(vec.feature_names_)   #查看转换后的别名\n",
    "print(\"x_train shape\",x_train.shape)\n",
    "print(\"x_test shape\",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train['rating'].values.reshape(-1,1)\n",
    "y_test=test['rating'].values.reshape(-1,1)\n",
    "print(\"y_train shape\",y_train.shape)\n",
    "print(\"y_test shape\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = Data.TensorDataset(torch.tensor(x_train),torch.tensor(y_train))\n",
    "test_dataset=Data.TensorDataset(torch.tensor(x_test),torch.tensor(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=25\n",
    "test_loader=Data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature,rating in test_loader:\n",
    "    print(feature.shape)\n",
    "    print(rating.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "    def __init__(self,feature_num,factor_num):\n",
    "        super(FM,self).__init__()\n",
    "        self.feature_num=feature_num\n",
    "        self.factor_num=factor_num\n",
    "        self.linear=nn.Linear(self.feature_num,1,bias=True) # Linear \n",
    "        self.v=nn.Parameter(torch.rand(self.feature_num,self.factor_num)) # Interaction\n",
    "        \n",
    "    def forward(self,x):\n",
    "        inter_1=torch.matmul(x,self.v).pow(2).sum(1,keepdim=True)\n",
    "        inter_2=torch.matmul(x.pow(2),self.v.pow(2)).sum(1,keepdim=True)\n",
    "        \n",
    "        out_inter=0.5*(inter_1-inter_2)\n",
    "        out_linear=self.linear(x)\n",
    "        \n",
    "        return out_inter+out_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num,feature_num=x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=FM(feature_num=feature_num,factor_num=5)\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=1e-2)\n",
    "loss_fn=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train_set=[]\n",
    "for epoch in range(35):\n",
    "    step=0\n",
    "    loss_sum=0.0\n",
    "    for batch_x,batch_y in tqdm(test_loader):\n",
    "        batch_x = batch_x.clone().detach().float()\n",
    "        batch_y = batch_y.clone().detach().float()\n",
    "        output=model(batch_x)\n",
    "        loss=loss_fn(output,batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(output.dtype)\n",
    "#         print(batch_y.dtype)\n",
    "#         break\n",
    "        loss_sum+=loss.item()\n",
    "        step+=1\n",
    "#     break\n",
    "    loss_train_set.append(loss_sum/step)\n",
    "    print('Loss of Epoch {}: {:.2f}'.format(epoch,loss_sum/step))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFM 的实现\n",
    "对于FFM，其差别是将特征的域区分开来，并认为域之间的交互是不同的，\n",
    "FM中的输入为[样本个数，特征维度]，\n",
    "\n",
    "FFM中的输入为[样本个数，域维度，特征维度]\n",
    "\n",
    "其实和FM是一样的，只不过求和的维度不一样而已，最后再一起求和\n",
    "\n",
    "不同域的特征维度可能不一样，但是其Embedding维度应该是一样的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature=df_test.drop(['rating'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>last_movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>27815.0</td>\n",
       "      <td>80831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>1356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>606.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>2355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>387.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20162</td>\n",
       "      <td>525.0</td>\n",
       "      <td>914.0</td>\n",
       "      <td>120807.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20163</td>\n",
       "      <td>606.0</td>\n",
       "      <td>27178.0</td>\n",
       "      <td>2355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20164</td>\n",
       "      <td>600.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6874.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20165</td>\n",
       "      <td>239.0</td>\n",
       "      <td>4022.0</td>\n",
       "      <td>8529.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20166</td>\n",
       "      <td>436.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20167 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user     item  last_movie\n",
       "0      560.0  27815.0     80831.0\n",
       "1       43.0    208.0      1356.0\n",
       "2      606.0    224.0      2355.0\n",
       "3       97.0    593.0       377.0\n",
       "4      387.0    296.0       348.0\n",
       "...      ...      ...         ...\n",
       "20162  525.0    914.0    120807.0\n",
       "20163  606.0  27178.0      2355.0\n",
       "20164  600.0    151.0      6874.0\n",
       "20165  239.0   4022.0      8529.0\n",
       "20166  436.0    450.0       568.0\n",
       "\n",
       "[20167 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\45395\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\45395\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\45395\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "field_list=[]\n",
    "for feature in df_feature.columns:\n",
    "    lbe=OneHotEncoder()\n",
    "    field_list.append(lbe.fit_transform(np.expand_dims(df_feature[feature].values,axis=1)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20167, 5134)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_list[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_list[0].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype=torch.FloatTensor\n",
    "class FFM(nn.Module):\n",
    "    \"\"\"\n",
    "    feature_num应该是一个列表，里面是不同域的维度\n",
    "    \"\"\"\n",
    "    def __init__(self,feature_num,field_num,factor_num):\n",
    "        super(FFM,self).__init__()\n",
    "        self.feature_num=feature_num\n",
    "        self.factor_num=factor_num\n",
    "        self.field_num=field_num\n",
    "        for index,fea_num in enumerate(feature_num):\n",
    "            setattr(self,\n",
    "                    'params_'+str(index),\n",
    "                    nn.Parameter(torch.rand(fea_num,factor_num)).type(dtype))\n",
    "            setattr(self,\n",
    "                    'linear_'+str(index),\n",
    "                    nn.Linear(fea_num,1,bias=True).type(dtype))\n",
    "            \n",
    "    def embedding(self,feature_list):\n",
    "        linear_sum=0\n",
    "        sample_num=feature_list[0].shape[0]\n",
    "        embedding_mat=torch.zeros([self.field_num,sample_num,self.factor_num])\n",
    "        for i in range(self.field_num):\n",
    "            linear_layer=getattr(self,'linear_'+str(i))\n",
    "            params=getattr(self,'params_'+str(i))\n",
    "            linear_sum+=linear_layer(feature_list[i])\n",
    "            embedding_mat[i,:]=torch.mm(feature_list[i],params)\n",
    "        \n",
    "        return linear_sum,embedding_mat\n",
    "    \n",
    "    def forward(self,x):\n",
    "        linear_sum,embedding_mat=self.embedding(x)\n",
    "        embedding_mat=embedding_mat.permute(1,0,2)\n",
    "        square_of_sum=torch.pow(torch.sum(embedding_mat,dim=1,keepdim=True),2)\n",
    "        sum_of_square=torch.sum(embedding_mat*embedding_mat,dim=1,keepdim=True)\n",
    "        cross_term=square_of_sum-sum_of_square\n",
    "        cross_term=0.5*torch.sum(cross_term,dim=2,keepdim=False)\n",
    "        \n",
    "        return linear_sum+cross_term\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num=np.array([feature.shape[1] for feature in field_list])\n",
    "field_num=feature_num.shape[0]\n",
    "factor_num=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 610, 5134,  510])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=FFM(feature_num,field_num,factor_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_list=[]\n",
    "for feature in field_list:\n",
    "    tensor_list.append(torch.tensor(feature[:4],dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7725],\n",
       "        [3.0419],\n",
       "        [2.4380],\n",
       "        [1.9246]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
